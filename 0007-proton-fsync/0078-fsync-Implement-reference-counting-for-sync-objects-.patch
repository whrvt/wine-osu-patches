From 067fd39a1e79416d8ca96925a48b395ab551a1ec Mon Sep 17 00:00:00 2001
From: Paul Gofman <pgofman@codeweavers.com>
Date: Mon, 4 Jul 2022 15:11:23 -0500
Subject: [PATCH 0562/1533] fsync: Implement reference counting for sync
 objects shared memory.

CW-Bug-Id: #20826
---
 dlls/ntdll/unix/fsync.c | 150 ++++++++++++++++++++++++++++++++++++----
 server/fsync.c          |  64 ++++++++++++++++-
 server/fsync.h          |   1 +
 server/process.c        |   6 +-
 server/protocol.def     |   5 ++
 5 files changed, 210 insertions(+), 16 deletions(-)

diff --git a/dlls/ntdll/unix/fsync.c b/dlls/ntdll/unix/fsync.c
index 0e3752421ed..309e2eb2aff 100644
--- a/dlls/ntdll/unix/fsync.c
+++ b/dlls/ntdll/unix/fsync.c
@@ -191,22 +191,28 @@ struct semaphore
 {
     int count;
     int max;
+    int ref;
+    int last_pid;
 };
-C_ASSERT(sizeof(struct semaphore) == 8);
+C_ASSERT(sizeof(struct semaphore) == 16);
 
 struct event
 {
     int signaled;
     int unused;
+    int ref;
+    int last_pid;
 };
-C_ASSERT(sizeof(struct event) == 8);
+C_ASSERT(sizeof(struct event) == 16);
 
 struct mutex
 {
     int tid;
     int count;  /* recursion count */
+    int ref;
+    int last_pid;
 };
-C_ASSERT(sizeof(struct mutex) == 8);
+C_ASSERT(sizeof(struct mutex) == 16);
 
 static char shm_name[29];
 static int shm_fd;
@@ -218,8 +224,8 @@ static pthread_mutex_t shm_addrs_mutex = PTHREAD_MUTEX_INITIALIZER;
 
 static void *get_shm( unsigned int idx )
 {
-    int entry  = (idx * 8) / pagesize;
-    int offset = (idx * 8) % pagesize;
+    int entry  = (idx * 16) / pagesize;
+    int offset = (idx * 16) % pagesize;
     void *ret;
 
     pthread_mutex_lock( &shm_addrs_mutex );
@@ -306,6 +312,59 @@ static void add_to_list( HANDLE handle, enum fsync_type type, unsigned int shm_i
     __atomic_store_n( (uint64_t *)&fsync_list[entry][idx], *(uint64_t *)&cache, __ATOMIC_SEQ_CST );
 }
 
+static void grab_object( struct fsync *obj )
+{
+    int *shm = obj->shm;
+
+    __atomic_add_fetch( &shm[2], 1, __ATOMIC_SEQ_CST );
+}
+
+static unsigned int shm_index_from_shm( char *shm )
+{
+    unsigned int count = shm_addrs_size;
+    unsigned int i, idx_offset;
+
+    for (i = 0; i < count; ++i)
+    {
+        if (shm >= (char *)shm_addrs[i] && shm < (char *)shm_addrs[i] + pagesize)
+        {
+            idx_offset = (shm - (char *)shm_addrs[i]) / 16;
+            return i * (pagesize / 16) + idx_offset;
+        }
+    }
+
+    ERR( "Index for shm %p not found.\n", shm );
+    return ~0u;
+}
+
+static void put_object( struct fsync *obj )
+{
+    int *shm = obj->shm;
+
+    if (__atomic_load_n( &shm[2], __ATOMIC_SEQ_CST ) == 1)
+    {
+        /* We are holding the last reference, it should be released on server so shm idx get freed. */
+        SERVER_START_REQ( fsync_free_shm_idx )
+        {
+            req->shm_idx = shm_index_from_shm( obj->shm );
+            wine_server_call( req );
+        }
+        SERVER_END_REQ;
+    }
+    else
+    {
+        __atomic_sub_fetch( &shm[2], 1, __ATOMIC_SEQ_CST );
+    }
+}
+
+static void put_object_from_wait( struct fsync *obj )
+{
+    int *shm = obj->shm;
+
+    __sync_val_compare_and_swap( &shm[3], GetCurrentProcessId(), 0 );
+    put_object( obj );
+}
+
 static BOOL get_cached_object( HANDLE handle, struct fsync *obj )
 {
     UINT_PTR entry, idx = handle_to_index( handle, &entry );
@@ -320,10 +379,13 @@ again:
 
     obj->type = cache.type;
     obj->shm = get_shm( cache.shm_idx );
-    if (*(uint64_t *)&cache != __atomic_load_n( (uint64_t *)&fsync_list[entry][idx], __ATOMIC_SEQ_CST ))
+    grab_object( obj );
+    if (((int *)obj->shm)[2] < 2 ||
+        *(uint64_t *)&cache != __atomic_load_n( (uint64_t *)&fsync_list[entry][idx], __ATOMIC_SEQ_CST ))
     {
         /* This check does not strictly guarantee that we avoid the potential race but is supposed to greatly
          * reduce the probability of that. */
+        put_object( obj );
         FIXME( "Cache changed while getting object.\n" );
         goto again;
     }
@@ -371,9 +433,24 @@ static NTSTATUS get_object( HANDLE handle, struct fsync *obj )
     obj->type = type;
     obj->shm = get_shm( shm_idx );
     add_to_list( handle, type, shm_idx );
+    /* get_fsync_idx server request increments shared mem refcount, so not grabbing object here. */
     return ret;
 }
 
+static NTSTATUS get_object_for_wait( HANDLE handle, struct fsync *obj )
+{
+    NTSTATUS ret;
+    int *shm;
+
+    if ((ret = get_object( handle, obj ))) return ret;
+
+    shm = obj->shm;
+    /* Give wineserver a chance to cleanup shm index if the process
+     * is killed while we are waiting on the object. */
+    __atomic_store_n( &shm[3], GetCurrentProcessId(), __ATOMIC_SEQ_CST );
+    return STATUS_SUCCESS;
+}
+
 NTSTATUS fsync_close( HANDLE handle )
 {
     UINT_PTR entry, idx = handle_to_index( handle, &entry );
@@ -540,13 +617,17 @@ NTSTATUS fsync_release_semaphore( HANDLE handle, ULONG count, ULONG *prev )
     {
         current = semaphore->count;
         if (count + current > semaphore->max)
+        {
+            put_object( &obj );
             return STATUS_SEMAPHORE_LIMIT_EXCEEDED;
+        }
     } while (__sync_val_compare_and_swap( &semaphore->count, current, count + current ) != current);
 
     if (prev) *prev = current;
 
     futex_wake( &semaphore->count, INT_MAX );
 
+    put_object( &obj );
     return STATUS_SUCCESS;
 }
 
@@ -566,6 +647,7 @@ NTSTATUS fsync_query_semaphore( HANDLE handle, void *info, ULONG *ret_len )
     out->MaximumCount = semaphore->max;
     if (ret_len) *ret_len = sizeof(*out);
 
+    put_object( &obj );
     return STATUS_SUCCESS;
 }
 
@@ -602,13 +684,17 @@ NTSTATUS fsync_set_event( HANDLE handle, LONG *prev )
     event = obj.shm;
 
     if (obj.type != FSYNC_MANUAL_EVENT && obj.type != FSYNC_AUTO_EVENT)
+    {
+        put_object( &obj );
         return STATUS_OBJECT_TYPE_MISMATCH;
+    }
 
     if (!(current = __atomic_exchange_n( &event->signaled, 1, __ATOMIC_SEQ_CST )))
         futex_wake( &event->signaled, INT_MAX );
 
     if (prev) *prev = current;
 
+    put_object( &obj );
     return STATUS_SUCCESS;
 }
 
@@ -628,6 +714,7 @@ NTSTATUS fsync_reset_event( HANDLE handle, LONG *prev )
 
     if (prev) *prev = current;
 
+    put_object( &obj );
     return STATUS_SUCCESS;
 }
 
@@ -657,6 +744,7 @@ NTSTATUS fsync_pulse_event( HANDLE handle, LONG *prev )
 
     if (prev) *prev = current;
 
+    put_object( &obj );
     return STATUS_SUCCESS;
 }
 
@@ -676,6 +764,7 @@ NTSTATUS fsync_query_event( HANDLE handle, void *info, ULONG *ret_len )
     out->EventType = (obj.type == FSYNC_AUTO_EVENT ? SynchronizationEvent : NotificationEvent);
     if (ret_len) *ret_len = sizeof(*out);
 
+    put_object( &obj );
     return STATUS_SUCCESS;
 }
 
@@ -708,7 +797,11 @@ NTSTATUS fsync_release_mutex( HANDLE handle, LONG *prev )
     if ((ret = get_object( handle, &obj ))) return ret;
     mutex = obj.shm;
 
-    if (mutex->tid != GetCurrentThreadId()) return STATUS_MUTANT_NOT_OWNED;
+    if (mutex->tid != GetCurrentThreadId())
+    {
+        put_object( &obj );
+        return STATUS_MUTANT_NOT_OWNED;
+    }
 
     if (prev) *prev = mutex->count;
 
@@ -718,6 +811,7 @@ NTSTATUS fsync_release_mutex( HANDLE handle, LONG *prev )
         futex_wake( &mutex->tid, INT_MAX );
     }
 
+    put_object( &obj );
     return STATUS_SUCCESS;
 }
 
@@ -738,6 +832,7 @@ NTSTATUS fsync_query_mutex( HANDLE handle, void *info, ULONG *ret_len )
     out->AbandonedState = (mutex->tid == ~0);
     if (ret_len) *ret_len = sizeof(*out);
 
+    put_object( &obj );
     return STATUS_SUCCESS;
 }
 
@@ -776,6 +871,14 @@ static NTSTATUS do_single_wait( int *addr, int val, const struct timespec64 *end
         return STATUS_PENDING;
 }
 
+static void put_objects( struct fsync *objs, unsigned int count )
+{
+    unsigned int i;
+
+    for (i = 0; i < count; ++i)
+        if (objs[i].type) put_object_from_wait( &objs[i] );
+}
+
 static NTSTATUS __fsync_wait_objects( DWORD count, const HANDLE *handles,
     BOOLEAN wait_any, BOOLEAN alertable, const LARGE_INTEGER *timeout )
 {
@@ -814,7 +917,7 @@ static NTSTATUS __fsync_wait_objects( DWORD count, const HANDLE *handles,
 
     for (i = 0; i < count; i++)
     {
-        ret = get_object( handles[i], &objs[i] );
+        ret = get_object_for_wait( handles[i], &objs[i] );
         if (ret == STATUS_SUCCESS)
         {
             assert( objs[i].type );
@@ -828,6 +931,7 @@ static NTSTATUS __fsync_wait_objects( DWORD count, const HANDLE *handles,
         }
         else
         {
+            put_objects( objs, i );
             return ret;
         }
     }
@@ -838,7 +942,10 @@ static NTSTATUS __fsync_wait_objects( DWORD count, const HANDLE *handles,
     if (has_fsync && has_server)
         FIXME("Can't wait on fsync and server objects at the same time!\n");
     else if (has_server)
+    {
+        put_objects( objs, count );
         return STATUS_NOT_IMPLEMENTED;
+    }
 
     if (TRACE_ON(fsync))
     {
@@ -893,6 +1000,7 @@ static NTSTATUS __fsync_wait_objects( DWORD count, const HANDLE *handles,
                         {
                             TRACE("Woken up by handle %p [%d].\n", handles[i], i);
                             if (waited) simulate_sched_quantum();
+                            put_objects( objs, count );
                             return i;
                         }
                         futex_vector_set( &futexes[i], &semaphore->count, 0 );
@@ -908,6 +1016,7 @@ static NTSTATUS __fsync_wait_objects( DWORD count, const HANDLE *handles,
                             TRACE("Woken up by handle %p [%d].\n", handles[i], i);
                             mutex->count++;
                             if (waited) simulate_sched_quantum();
+                            put_objects( objs, count );
                             return i;
                         }
 
@@ -916,12 +1025,14 @@ static NTSTATUS __fsync_wait_objects( DWORD count, const HANDLE *handles,
                             TRACE("Woken up by handle %p [%d].\n", handles[i], i);
                             mutex->count = 1;
                             if (waited) simulate_sched_quantum();
+                            put_objects( objs, count );
                             return i;
                         }
                         else if (tid == ~0 && (tid = __sync_val_compare_and_swap( &mutex->tid, ~0, GetCurrentThreadId() )) == ~0)
                         {
                             TRACE("Woken up by abandoned mutex %p [%d].\n", handles[i], i);
                             mutex->count = 1;
+                            put_objects( objs, count );
                             return STATUS_ABANDONED_WAIT_0 + i;
                         }
 
@@ -940,6 +1051,7 @@ static NTSTATUS __fsync_wait_objects( DWORD count, const HANDLE *handles,
 
                             TRACE("Woken up by handle %p [%d].\n", handles[i], i);
                             if (waited) simulate_sched_quantum();
+                            put_objects( objs, count );
                             return i;
                         }
                         futex_vector_set( &futexes[i], &event->signaled, 0 );
@@ -958,6 +1070,7 @@ static NTSTATUS __fsync_wait_objects( DWORD count, const HANDLE *handles,
 
                             TRACE("Woken up by handle %p [%d].\n", handles[i], i);
                             if (waited) simulate_sched_quantum();
+                            put_objects( objs, count );
                             return i;
                         }
                         futex_vector_set( &futexes[i], &event->signaled, 0 );
@@ -992,6 +1105,7 @@ static NTSTATUS __fsync_wait_objects( DWORD count, const HANDLE *handles,
                 /* Unlike esync, we already know that we've timed out, so we
                  * can avoid a syscall. */
                 TRACE("Wait timed out.\n");
+                put_objects( objs, count );
                 return STATUS_TIMEOUT;
             }
 
@@ -1004,6 +1118,7 @@ static NTSTATUS __fsync_wait_objects( DWORD count, const HANDLE *handles,
             if (ret == -1 && errno == ETIMEDOUT)
             {
                 TRACE("Wait timed out.\n");
+                put_objects( objs, count );
                 return STATUS_TIMEOUT;
             }
             else waited = TRUE;
@@ -1078,6 +1193,7 @@ tryagain:
                 if (status == STATUS_TIMEOUT)
                 {
                     TRACE("Wait timed out.\n");
+                    put_objects( objs, count );
                     return status;
                 }
                 else if (status == STATUS_USER_APC)
@@ -1167,9 +1283,11 @@ tryagain:
             if (abandoned)
             {
                 TRACE("Wait successful, but some object(s) were abandoned.\n");
+                put_objects( objs, count );
                 return STATUS_ABANDONED;
             }
             TRACE("Wait successful.\n");
+            put_objects( objs, count );
             return STATUS_SUCCESS;
 
 tooslow:
@@ -1214,6 +1332,8 @@ tooslow:
 userapc:
     TRACE("Woken up by user APC.\n");
 
+    put_objects( objs, count );
+
     /* We have to make a server call anyway to get the APC to execute, so just
      * delegate down to server_wait(). */
     ret = server_wait( NULL, 0, SELECT_INTERRUPTIBLE | SELECT_ALERTABLE, &zero );
@@ -1253,10 +1373,14 @@ NTSTATUS fsync_wait_objects( DWORD count, const HANDLE *handles, BOOLEAN wait_an
     struct fsync obj;
     NTSTATUS ret;
 
-    if (count && !get_object( handles[count - 1], &obj ) && obj.type == FSYNC_QUEUE)
+    if (count && !get_object( handles[count - 1], &obj ))
     {
-        msgwait = TRUE;
-        server_set_msgwait( 1 );
+        if (obj.type == FSYNC_QUEUE)
+        {
+            msgwait = TRUE;
+            server_set_msgwait( 1 );
+        }
+        put_object( &obj );
     }
 
     ret = __fsync_wait_objects( count, handles, wait_any, alertable, timeout );
@@ -1288,8 +1412,10 @@ NTSTATUS fsync_signal_and_wait( HANDLE signal, HANDLE wait, BOOLEAN alertable,
         ret = fsync_release_mutex( signal, NULL );
         break;
     default:
-        return STATUS_OBJECT_TYPE_MISMATCH;
+        ret = STATUS_OBJECT_TYPE_MISMATCH;
+        break;
     }
+    put_object( &obj );
     if (ret) return ret;
 
     return fsync_wait_objects( 1, &wait, TRUE, alertable, timeout );
diff --git a/server/fsync.c b/server/fsync.c
index 3c1e709d7e3..0e3862389da 100644
--- a/server/fsync.c
+++ b/server/fsync.c
@@ -205,8 +205,8 @@ static void fsync_destroy( struct object *obj )
 
 static void *get_shm( unsigned int idx )
 {
-    int entry  = (idx * 8) / pagesize;
-    int offset = (idx * 8) % pagesize;
+    int entry  = (idx * 16) / pagesize;
+    int offset = (idx * 16) % pagesize;
 
     if (entry >= shm_addrs_size)
     {
@@ -287,7 +287,7 @@ unsigned int fsync_alloc_shm( int low, int high )
         shm_idx = alloc_shm_idx_from_word( old_size );
     }
 
-    while (shm_idx * 8 >= shm_size)
+    while (shm_idx * 16 >= shm_size)
     {
         /* Better expand the shm section. */
         shm_size += pagesize;
@@ -303,6 +303,8 @@ unsigned int fsync_alloc_shm( int low, int high )
     assert(shm);
     shm[0] = low;
     shm[1] = high;
+    shm[2] = 1; /* Reference count. */
+    shm[3] = 0; /* Last reference process id. */
 
     return shm_idx;
 #else
@@ -314,9 +316,24 @@ void fsync_free_shm_idx( int shm_idx )
 {
     unsigned int idx;
     uint64_t mask;
+    int *shm;
 
     assert( shm_idx );
     assert( shm_idx < shm_idx_free_map_size * BITS_IN_FREE_MAP_WORD );
+
+    shm = get_shm( shm_idx );
+    if (shm[2] <= 0)
+    {
+        fprintf( stderr, "wineserver: fsync err: shm refcount is %d.\n", shm[2] );
+        return;
+    }
+
+    if (__atomic_sub_fetch( &shm[2], 1, __ATOMIC_SEQ_CST ))
+    {
+        /* Sync object is still referenced in a process. */
+        return;
+    }
+
     idx = shm_idx / BITS_IN_FREE_MAP_WORD;
     mask = (uint64_t)1 << (shm_idx % BITS_IN_FREE_MAP_WORD);
     assert( !(shm_idx_free_map[idx] & mask) );
@@ -325,6 +342,31 @@ void fsync_free_shm_idx( int shm_idx )
         shm_idx_free_search_start_hint = idx;
 }
 
+/* Try to cleanup the shared mem indices locked by the wait on the killed processes.
+ * This is not fully reliable but should avoid leaking the majority of indices on
+ * process kill. */
+void fsync_cleanup_process_shm_indices( process_id_t id )
+{
+    uint64_t free_word;
+    unsigned int i, j;
+    void *shmbase;
+    int *shm;
+
+    for (i = 0; i < shm_idx_free_map_size; ++i)
+    {
+        free_word = shm_idx_free_map[i];
+        if (free_word == ~(uint64_t)0) continue;
+        shmbase = get_shm( i * BITS_IN_FREE_MAP_WORD );
+        for (j = !i; j < BITS_IN_FREE_MAP_WORD; ++j)
+        {
+            shm = (int *)((char *)shmbase + j * 16);
+            if (!(free_word & ((uint64_t)1 << j)) && shm[3] == id
+                  && __atomic_load_n( &shm[2], __ATOMIC_SEQ_CST ) == 1)
+                fsync_free_shm_idx( i * BITS_IN_FREE_MAP_WORD + j );
+        }
+    }
+}
+
 static int type_matches( enum fsync_type type1, enum fsync_type type2 )
 {
     return (type1 == type2) ||
@@ -384,6 +426,8 @@ struct fsync_event
 {
     int signaled;
     int unused;
+    int ref;
+    int last_pid;
 };
 
 void fsync_wake_futex( unsigned int shm_idx )
@@ -551,8 +595,12 @@ DECL_HANDLER(get_fsync_idx)
 
     if (obj->ops->get_fsync_idx)
     {
+        int *shm;
+
         reply->shm_idx = obj->ops->get_fsync_idx( obj, &type );
         reply->type = type;
+        shm = get_shm( reply->shm_idx );
+        __atomic_add_fetch( &shm[2], 1, __ATOMIC_SEQ_CST );
     }
     else
     {
@@ -571,3 +619,13 @@ DECL_HANDLER(get_fsync_apc_idx)
 {
     reply->shm_idx = current->fsync_apc_idx;
 }
+
+DECL_HANDLER(fsync_free_shm_idx)
+{
+    if (!req->shm_idx || req->shm_idx >= shm_idx_free_map_size * BITS_IN_FREE_MAP_WORD)
+    {
+        set_error( STATUS_INVALID_PARAMETER );
+        return;
+    }
+    fsync_free_shm_idx( req->shm_idx );
+}
diff --git a/server/fsync.h b/server/fsync.h
index ee1a729e77e..d4bd889a7f8 100644
--- a/server/fsync.h
+++ b/server/fsync.h
@@ -33,3 +33,4 @@ extern const struct object_ops fsync_ops;
 extern void fsync_set_event( struct fsync *fsync );
 extern void fsync_reset_event( struct fsync *fsync );
 extern void fsync_abandon_mutexes( struct thread *thread );
+extern void fsync_cleanup_process_shm_indices( process_id_t id );
diff --git a/server/process.c b/server/process.c
index d43df3d15f6..8b867a26c8a 100644
--- a/server/process.c
+++ b/server/process.c
@@ -805,7 +805,11 @@ static void process_destroy( struct object *obj )
     free( process->dir_cache );
     free( process->image );
     if (do_esync()) close( process->esync_fd );
-    if (process->fsync_idx) fsync_free_shm_idx( process->fsync_idx );
+    if (process->fsync_idx)
+    {
+        fsync_cleanup_process_shm_indices( process->id );
+        fsync_free_shm_idx( process->fsync_idx );
+    }
 }
 
 /* dump a process on stdout for debugging purposes */
diff --git a/server/protocol.def b/server/protocol.def
index 2d91baf245a..9d211b683eb 100644
--- a/server/protocol.def
+++ b/server/protocol.def
@@ -4045,3 +4045,8 @@ enum fsync_type
 @REPLY
     unsigned int shm_idx;
 @END
+
+@REQ(fsync_free_shm_idx)
+    unsigned int shm_idx;
+@REPLY
+@END
-- 
2.45.0

