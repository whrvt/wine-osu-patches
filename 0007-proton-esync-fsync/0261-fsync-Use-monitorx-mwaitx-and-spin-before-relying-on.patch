From 478b891109bfee55921d9af0ff75706f277096b5 Mon Sep 17 00:00:00 2001
From: William Horvath <william@horvath.blog>
Date: Mon, 11 Nov 2024 18:27:50 -0800
Subject: [PATCH v2] fsync: Use monitorx+mwaitx and spin before relying on
 futex_waitv in wait-all.

Taking inspiration from a patch by Torge Matthies.

v2: Fix mutex reacquire to use atomic operations, general reorganization.
---
 dlls/ntdll/unix/fsync.c | 94 ++++++++++++++++++++++++++++++++++++++---
 dlls/ntdll/unix/fsync.h | 62 +++++++++++++++++++++++++++
 2 files changed, 151 insertions(+), 5 deletions(-)

diff --git a/dlls/ntdll/unix/fsync.c b/dlls/ntdll/unix/fsync.c
index 169ceab10ad..eb74b658b0c 100644
--- a/dlls/ntdll/unix/fsync.c
+++ b/dlls/ntdll/unix/fsync.c
@@ -773,6 +773,72 @@ static NTSTATUS do_single_wait( int *addr, int val, const struct timespec64 *end
         return STATUS_PENDING;
 }
 
+#define MUTEX_MON_TIMEOUT     1000
+#define MUTEX_BASE_SPIN       2
+#define AUTO_MON_TIMEOUT      1000
+#define AUTO_BASE_SPIN        3
+#define MANUAL_MON_TIMEOUT    2000
+#define MANUAL_BASE_SPIN      4
+
+/* Fast path attempt to detect a value change using monitorx/mwaitx and spinning.
+ * Returns STATUS_SUCCESS if the value changed, STATUS_UNSUCCESSFUL otherwise.
+ *
+ * Parameters:
+ *   addr         - Memory address to monitor
+ *   expected_val - Value we're waiting to change
+ *   observed_val - If non-NULL, receives the last observed value
+ *   mon_timeout  - Max cycles to wait in mwaitx
+ *   base_spin    - # of spin iterations (mwaitx being unavailable will add 2 to base_spin)
+ */
+static inline NTSTATUS try_wait_value( volatile int *addr, int expected_val, int *observed_val,
+    const unsigned int mon_timeout, const unsigned int base_spin )
+{
+    static const unsigned int MIN_SPIN_ITERS = 4;
+    static const unsigned int SPIN_SHIFT = 4;
+    unsigned int spin_i, spin_o;
+    const unsigned int max_spin = mwaitx_supported() ? base_spin : base_spin + 2;
+    int val;
+    NTSTATUS status = STATUS_UNSUCCESSFUL;
+
+    /* Fast path - check current value before waiting */
+    val = __atomic_load_n( addr, __ATOMIC_SEQ_CST );
+    if (val != expected_val) {
+        status = STATUS_SUCCESS;
+        goto done;
+    }
+
+    /* Try hardware wait if available */
+    if (mwaitx_supported())
+    {
+        val = monitor_wait( addr, expected_val, mon_timeout );
+        if (val != expected_val) {
+            status = STATUS_SUCCESS;
+            goto done;
+        }
+    }
+
+    /* Try spinning with exponential backoff */
+    do {
+        val = __atomic_load_n( addr, __ATOMIC_SEQ_CST );
+        if (val != expected_val) {
+            status = STATUS_SUCCESS;
+            goto done;
+        }
+
+        /* backoff iterations: min(MIN_SPIN_ITERS, 2^(spin-SHIFT)) */
+        spin_i = (spin_o <= SPIN_SHIFT) ? MIN_SPIN_ITERS
+                                        : (1U << (spin_o - SPIN_SHIFT));
+        do {
+            YieldProcessor();
+        } while (--spin_i);
+    } while (++spin_o < max_spin);
+
+done:
+    if (observed_val)
+        *observed_val = val;
+    return status;
+}
+
 static NTSTATUS __fsync_wait_objects( DWORD count, const HANDLE *handles,
     BOOLEAN wait_any, BOOLEAN alertable, const LARGE_INTEGER *timeout )
 {
@@ -908,27 +974,31 @@ static NTSTATUS __fsync_wait_objects( DWORD count, const HANDLE *handles,
                     {
                         struct mutex *mutex = obj->shm;
                         int tid;
-
+                        unsigned int try = 0;
+reacquire_mutex:
                         if (mutex->tid == current_tid)
                         {
-                            TRACE("Woken up by handle %p [%d].\n", handles[i], i);
+                            TRACE("Woken up by handle %p [%d] try_wait %u.\n", handles[i], i, try);
                             mutex->count++;
                             return i;
                         }
 
                         if (!(tid = __sync_val_compare_and_swap( &mutex->tid, 0, current_tid )))
                         {
-                            TRACE("Woken up by handle %p [%d].\n", handles[i], i);
+                            TRACE("Woken up by handle %p [%d] try_wait %u.\n", handles[i], i, try);
                             mutex->count = 1;
                             return i;
                         }
                         else if (tid == ~0 && (tid = __sync_val_compare_and_swap( &mutex->tid, ~0, current_tid )) == ~0)
                         {
-                            TRACE("Woken up by abandoned mutex %p [%d].\n", handles[i], i);
+                            TRACE("Woken up by abandoned mutex %p [%d] try_wait %u.\n", handles[i], i, try);
                             mutex->count = 1;
                             return STATUS_ABANDONED_WAIT_0 + i;
                         }
 
+                        if (!try++ && try_wait_value( &mutex->tid, tid, &tid, MUTEX_MON_TIMEOUT, MUTEX_BASE_SPIN ) == STATUS_SUCCESS)
+                            goto reacquire_mutex;
+
                         futex_vector_set( &futexes[i], &mutex->tid, tid );
                         break;
                     }
@@ -942,6 +1012,13 @@ static NTSTATUS __fsync_wait_objects( DWORD count, const HANDLE *handles,
                             TRACE("Woken up by handle %p [%d].\n", handles[i], i);
                             return i;
                         }
+                        int signaled;
+                        if (try_wait_value( &event->signaled, 0, &signaled, AUTO_MON_TIMEOUT, AUTO_BASE_SPIN ) == STATUS_SUCCESS &&
+                            signaled && __sync_val_compare_and_swap( &event->signaled, 1, 0 ))
+                        {
+                            TRACE("Woken up by handle %p [%d].\n", handles[i], i);
+                            return i;
+                        }
                         futex_vector_set( &futexes[i], &event->signaled, 0 );
                         break;
                     }
@@ -950,8 +1027,15 @@ static NTSTATUS __fsync_wait_objects( DWORD count, const HANDLE *handles,
                     case FSYNC_QUEUE:
                     {
                         struct event *event = obj->shm;
+                        int signaled = __atomic_load_n( &event->signaled, __ATOMIC_SEQ_CST );
+
+                        if (signaled)
+                        {
+                            TRACE("Woken up by handle %p [%d].\n", handles[i], i);
+                            return i;
+                        }
 
-                        if (__atomic_load_n( &event->signaled, __ATOMIC_SEQ_CST ))
+                        if (try_wait_value( &event->signaled, 0, &signaled, MANUAL_MON_TIMEOUT, MANUAL_BASE_SPIN ) == STATUS_SUCCESS && signaled)
                         {
                             TRACE("Woken up by handle %p [%d].\n", handles[i], i);
                             return i;
diff --git a/dlls/ntdll/unix/fsync.h b/dlls/ntdll/unix/fsync.h
index 59013f83e7c..63691a0d207 100644
--- a/dlls/ntdll/unix/fsync.h
+++ b/dlls/ntdll/unix/fsync.h
@@ -58,3 +58,65 @@ static inline int get_cached_tid(void)
     static __thread int cached_tid;
     return cached_tid ? cached_tid : (cached_tid = GetCurrentThreadId());
 }
+
+#if defined(__x86_64__) || defined(__i386__)
+
+static inline int mwaitx_supported( void )
+{
+    static int supported;
+    if (!supported)
+    {
+        unsigned int eax, ecx;
+        __asm__ __volatile__ (
+            "cpuid"
+            : "=a" (eax), "=c" (ecx)
+            : "a" (0x80000001U)
+            : "ebx", "edx"
+        );
+        if (ecx & (1U << 29))
+            supported = 1;
+        else
+            supported = -1;
+    }
+    return supported > 0;
+}
+
+/* Monitor memory location for changes using MONITORX/MWAITX
+ * addr: Memory address to monitor 
+ * val: Expected value
+ * timeout: Max cycles to wait
+ * Returns: The current value at addr after monitoring
+ * 
+ * Note: monitorx/mwaitx act as full memory barriers, so this
+ * function provides sequential consistency for the monitored address */
+static inline int monitor_wait( volatile int *addr, int val, unsigned int timeout )
+{
+    /* monitorx setup - acts as acquire barrier */
+    __asm__ __volatile__ (
+        ".byte 0x0f,0x01,0xfa" /* monitorx */
+        :
+        : "a" (addr), "c" (0U), "d" (0U)
+        : "memory"
+    );
+
+    /* The value check is done after monitorx since monitorx 
+     * acts as an acquire barrier - if the value changed, we'll see it */
+    if (*addr != val)
+        return *addr;
+
+    /* mwaitx - acts as full barrier */    
+    __asm__ __volatile__ (
+        ".byte 0x0f,0x01,0xfb" /* mwaitx */
+        :
+        : "a" (0xF0U), "b" (timeout), "c" (0x2U)
+        : "memory"
+    );
+
+    /* mwaitx ensures we see latest value */
+    return *addr;
+}
+
+#else
+#define mwaitx_supported() 0
+static inline int monitor_wait( volatile int *addr, int val, unsigned int timeout ) {}
+#endif
-- 
2.47.0

