From 5359f9cc7977453835b679b2a4c6213ee79b345a Mon Sep 17 00:00:00 2001
From: William Horvath <william@horvath.blog>
Date: Mon, 6 Jan 2025 10:14:56 -0800
Subject: [PATCH] fsync: Make fsync_cache pointer-sized.

---
 dlls/ntdll/unix/fsync.c | 20 ++++++++++++++------
 1 file changed, 14 insertions(+), 6 deletions(-)

diff --git a/dlls/ntdll/unix/fsync.c b/dlls/ntdll/unix/fsync.c
index c3da44e4f26..7d12fbc6547 100644
--- a/dlls/ntdll/unix/fsync.c
+++ b/dlls/ntdll/unix/fsync.c
@@ -255,13 +255,21 @@ static void *get_shm( unsigned int idx )
 #define FSYNC_LIST_BLOCK_SIZE  (65536 / sizeof(struct fsync))
 #define FSYNC_LIST_ENTRIES     256
 
+#ifdef __i386__
+struct fsync_cache
+{
+    enum fsync_type type:3;
+    unsigned int shm_idx:29;
+};
+#else
 struct fsync_cache
 {
     enum fsync_type type;
     unsigned int shm_idx;
 };
+#endif
 
-C_ASSERT(sizeof(struct fsync_cache) == sizeof(uint64_t));
+C_ASSERT(sizeof(struct fsync_cache) == sizeof(UINT_PTR));
 
 static struct fsync_cache *fsync_list[FSYNC_LIST_ENTRIES];
 static struct fsync_cache fsync_list_initial_block[FSYNC_LIST_BLOCK_SIZE];
@@ -299,7 +307,7 @@ static void add_to_list( HANDLE handle, enum fsync_type type, unsigned int shm_i
 
     cache.type = type;
     cache.shm_idx = shm_idx;
-    __atomic_store_n( (uint64_t *)&fsync_list[entry][idx], *(uint64_t *)&cache, __ATOMIC_SEQ_CST );
+    __atomic_store_n( (UINT_PTR *)&fsync_list[entry][idx], *(UINT_PTR *)&cache, __ATOMIC_SEQ_CST );
 }
 
 static void grab_object( struct fsync *obj )
@@ -362,7 +370,7 @@ static BOOL get_cached_object( HANDLE handle, struct fsync *obj )
     if (entry >= FSYNC_LIST_ENTRIES || !fsync_list[entry]) return FALSE;
 
 again:
-    *(uint64_t *)&cache = __atomic_load_n( (uint64_t *)&fsync_list[entry][idx], __ATOMIC_SEQ_CST );
+    *(UINT_PTR *)&cache = __atomic_load_n( (UINT_PTR *)&fsync_list[entry][idx], __ATOMIC_SEQ_CST );
 
     if (!cache.type || !cache.shm_idx) return FALSE;
 
@@ -370,7 +378,7 @@ static BOOL get_cached_object( HANDLE handle, struct fsync *obj )
     obj->shm = get_shm( cache.shm_idx );
     grab_object( obj );
     if (((int *)obj->shm)[2] < 2 ||
-        *(uint64_t *)&cache != __atomic_load_n( (uint64_t *)&fsync_list[entry][idx], __ATOMIC_SEQ_CST ))
+        *(UINT_PTR *)&cache != __atomic_load_n( (UINT_PTR *)&fsync_list[entry][idx], __ATOMIC_SEQ_CST ))
     {
         /* This check does not strictly guarantee that we avoid the potential race but is supposed to greatly
          * reduce the probability of that. */
@@ -469,8 +477,8 @@ NTSTATUS fsync_close( HANDLE handle )
 
         cache.type = 0;
         cache.shm_idx = 0;
-        *(uint64_t *)&cache = __atomic_exchange_n( (uint64_t *)&fsync_list[entry][idx],
-                                                   *(uint64_t *)&cache, __ATOMIC_SEQ_CST );
+        *(UINT_PTR *)&cache = __atomic_exchange_n( (UINT_PTR *)&fsync_list[entry][idx],
+                                                   *(UINT_PTR *)&cache, __ATOMIC_SEQ_CST );
         if (cache.type) return STATUS_SUCCESS;
     }
 
